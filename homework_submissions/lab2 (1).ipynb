{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355fd65f-56fc-47fb-aa02-2598f00e21d9",
   "metadata": {},
   "source": [
    "## Course Assignment Instructions\n",
    "You should have Python (version 3.8 or later) and Jupyter Notebook installed to complete this assignment. You will write code in the empty cell/cells below the problem. While most of this will be a programming assignment, some questions will ask you to \"write a few sentences\" in markdown cells. \n",
    "\n",
    "Submission Instructions:\n",
    "\n",
    "Create a labs directory in your personal class repository (e.g., located in your home directory)\n",
    "Clone the class repository\n",
    "Copy this Jupyter notebook file (.ipynb) into your repo/labs directory\n",
    "Make your edits, commit changes, and push to your repository\n",
    "All submissions must be pushed before the due date to avoid late penalties. \n",
    "\n",
    "Labs are graded out of a 100 pts. Each day late is -5. For a max penalty of -50 after 10 days. From there you may submit the lab anytime before the semester ends for a max score of 50.  \n",
    "\n",
    "Lab 2 is due on 2/18/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffbbc2-9164-463a-895e-da75b2598f51",
   "metadata": {},
   "source": [
    "## Basic Modeling\n",
    "In the 342 class an example was given that considered a variable `x_3` which measured \"criminality\". In this example there are L = 4 levels \"none\", \"infraction\", \"misdemeanor\" and \"felony\". Create a variable `x_3` here with 100 random elements (equally probable). Create it as a nominal (i.e. unordered) factor. Hint: use random.choice from NumPy and Categorical from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce74aa8b-aa8d-4443-917a-dd6846f6b9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['misdemeanor', 'misdemeanor', 'felony', 'misdemeanor', 'misdemeanor', ..., 'none', 'none', 'misdemeanor', 'none', 'misdemeanor']\n",
       "Length: 100\n",
       "Categories (4, object): ['none', 'infraction', 'misdemeanor', 'felony']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the categories\n",
    "\n",
    "categories = [\"none\",\"infraction\",\"misdemeanor\",\"felony\"]\n",
    "\n",
    "\n",
    "# Generate 100 random elements with equal probability\n",
    "\n",
    "x_3 = np.random.choice(categories, size = 100, replace = True)\n",
    "\n",
    "# Convert to a categorical (nominal- \"nominal\" refers to a type of \n",
    "#categorical data where values represent distinct categories \n",
    "#without any inherent order or ranking) variable in pandas\n",
    "\n",
    "x_3 = pd.Categorical(x_3, categories = categories, ordered = False)\n",
    "x_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6e027-0803-4f80-9fee-361a1ea53d25",
   "metadata": {},
   "source": [
    "Use x_3 to create x_3_bin, a binary feature where 0 is no crime and 1 is any crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670e525b-267b-4b5c-854e-09eb42f33df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a boolean array (True for crime, False for no crime)\n",
    "x_3_bin = (x_3!=\"none\").astype(int)\n",
    "x_3_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6105c8e-80eb-47bb-a088-ea567b19df8c",
   "metadata": {},
   "source": [
    "Use `x_3` to create `x_3_ord`, an ordered factor variable. Ensure the proper ordinal ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e0d1ca-9957-4130-b550-962e3e86c954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['misdemeanor', 'misdemeanor', 'felony', 'misdemeanor', 'misdemeanor', ..., 'none', 'none', 'misdemeanor', 'none', 'misdemeanor']\n",
       "Length: 100\n",
       "Categories (4, object): ['infraction' < 'none' < 'misdemeanor' < 'felony']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\"infraction\",\"none\",\"misdemeanor\",\"felony\"]\n",
    "x_3_ord=pd.Categorical(x_3, categories = categories, ordered = True)\n",
    "x_3_ord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659559c0-9a34-4c38-af71-c6c9910f7ff2",
   "metadata": {},
   "source": [
    "Convert this variable into three binary variables without any information loss and put them into a data matrix. Hint: use column_stack from Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06455be9-05b2-486d-ac5c-08dbad0566ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infraction</th>\n",
       "      <th>misdemeanor</th>\n",
       "      <th>felony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    infraction  misdemeanor  felony\n",
       "0            0            0       1\n",
       "1            0            0       1\n",
       "2            0            1       0\n",
       "3            0            0       1\n",
       "4            0            0       1\n",
       "..         ...          ...     ...\n",
       "95           0            0       0\n",
       "96           0            0       0\n",
       "97           0            0       1\n",
       "98           0            0       0\n",
       "99           0            0       1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes all 3 arrays and makes matrix of it/stacks it together\n",
    "x_3_matrix = np.column_stack([\n",
    "    (x_3 == \"infraction\").astype(int),\n",
    "    (x_3 == \"felony\").astype(int),\n",
    "    (x_3 == \"misdemeanor\").astype(int)\n",
    "]\n",
    ")\n",
    "# now convert to matrix using pandas\n",
    "\n",
    "x_3_matrix = pd.DataFrame(x_3_matrix, columns = [\"infraction\",\"misdemeanor\",\"felony\"])\n",
    "x_3_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225f1e4-57dd-43f4-9c3e-391698dec745",
   "metadata": {},
   "source": [
    "What should the sum of each row be (in English)? Write your answer in the markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdce95-f726-46aa-b3cc-2caa76a25477",
   "metadata": {},
   "source": [
    " each row should be 1 or 0 so sum will be 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5770e1-d384-4199-bf8b-f92b6f637c56",
   "metadata": {},
   "source": [
    "Verify that in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd86eeff-5d4d-4de8-83e9-07de66f220ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "0    18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "row_sum = x_3_matrix.sum(axis = 1)\n",
    "#axis = 1 is row and =0 is columns\n",
    "row_sum\n",
    "print(row_sum.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdfff3-9476-46d7-acc2-8fd13bfe7eed",
   "metadata": {},
   "source": [
    " How should the column sum look (in English)? Write your answer in the markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aed132-b84d-4084-b242-eda992feb249",
   "metadata": {},
   "source": [
    "atleast 0 atmost n - approximately 25 per column cb we sampled 4 categories evenly from 100 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319576be-978e-4130-8c16-82206d42558e",
   "metadata": {},
   "source": [
    "Verify that in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2346133a-e7be-4964-8c5e-1d202c5218b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infraction     27\n",
      "misdemeanor    27\n",
      "felony         28\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_sum = x_3_matrix.sum(axis = 0) \n",
    "print(col_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cf75f-aee2-47eb-b6c7-7ef9067e0721",
   "metadata": {},
   "source": [
    "Generate a matrix with 100 rows where the first column is realization from a normal with mean 17 and variance 38, the second column is uniform between -10 and 10, the third column is poisson with mean 6, the fourth column is exponential with lambda of 9, the fifth column is binomial with n = 20 and p = 0.12 and the sixth column is a binary variable with exactly 24% 1's dispersed randomly. Name the rows the entries of the `fake_first_names` vector. You will need to use Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67db4b39-b1d9-4848-a330-1f11c6cacbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Uniform</th>\n",
       "      <th>Poisson</th>\n",
       "      <th>Exponential</th>\n",
       "      <th>Binomial</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sophia</th>\n",
       "      <td>19.146136</td>\n",
       "      <td>8.059100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emma</th>\n",
       "      <td>20.248167</td>\n",
       "      <td>0.657792</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040585</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olivia</th>\n",
       "      <td>17.212600</td>\n",
       "      <td>1.664471</td>\n",
       "      <td>8</td>\n",
       "      <td>0.079142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ava</th>\n",
       "      <td>23.937950</td>\n",
       "      <td>-0.799742</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mia</th>\n",
       "      <td>10.306851</td>\n",
       "      <td>1.941303</td>\n",
       "      <td>7</td>\n",
       "      <td>0.123583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christian</th>\n",
       "      <td>18.757201</td>\n",
       "      <td>7.606783</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew</th>\n",
       "      <td>10.981748</td>\n",
       "      <td>-0.557392</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brayden</th>\n",
       "      <td>7.108700</td>\n",
       "      <td>9.718888</td>\n",
       "      <td>7</td>\n",
       "      <td>0.068551</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>14.021473</td>\n",
       "      <td>0.948379</td>\n",
       "      <td>4</td>\n",
       "      <td>0.107377</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lincoln</th>\n",
       "      <td>17.295381</td>\n",
       "      <td>7.376450</td>\n",
       "      <td>3</td>\n",
       "      <td>0.204942</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Normal   Uniform  Poisson  Exponential  Binomial  Binary\n",
       "Sophia     19.146136  8.059100        9     0.246700         2       0\n",
       "Emma       20.248167  0.657792        7     0.040585         1       0\n",
       "Olivia     17.212600  1.664471        8     0.079142         1       0\n",
       "Ava        23.937950 -0.799742        3     0.105012         5       0\n",
       "Mia        10.306851  1.941303        7     0.123583         0       0\n",
       "...              ...       ...      ...          ...       ...     ...\n",
       "Christian  18.757201  7.606783        3     0.166500         7       0\n",
       "Andrew     10.981748 -0.557392        5     0.037886         1       0\n",
       "Brayden     7.108700  9.718888        7     0.068551         3       0\n",
       "John       14.021473  0.948379        4     0.107377         2       0\n",
       "Lincoln    17.295381  7.376450        3     0.204942         1       1\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows\n",
    "num_rows = 100\n",
    "\n",
    "# Assign row names (index) from fake_first_names\n",
    "fake_first_names = [\n",
    "    \"Sophia\", \"Emma\", \"Olivia\", \"Ava\", \"Mia\", \"Isabella\", \"Riley\", \n",
    "    \"Aria\", \"Zoe\", \"Charlotte\", \"Lily\", \"Layla\", \"Amelia\", \"Emily\", \n",
    "    \"Madelyn\", \"Aubrey\", \"Adalyn\", \"Madison\", \"Chloe\", \"Harper\", \n",
    "    \"Abigail\", \"Aaliyah\", \"Avery\", \"Evelyn\", \"Kaylee\", \"Ella\", \"Ellie\", \n",
    "    \"Scarlett\", \"Arianna\", \"Hailey\", \"Nora\", \"Addison\", \"Brooklyn\", \n",
    "    \"Hannah\", \"Mila\", \"Leah\", \"Elizabeth\", \"Sarah\", \"Eliana\", \"Mackenzie\", \n",
    "    \"Peyton\", \"Maria\", \"Grace\", \"Adeline\", \"Elena\", \"Anna\", \"Victoria\", \n",
    "    \"Camilla\", \"Lillian\", \"Natalie\", \"Jackson\", \"Aiden\", \"Lucas\", \n",
    "    \"Liam\", \"Noah\", \"Ethan\", \"Mason\", \"Caden\", \"Oliver\", \"Elijah\", \n",
    "    \"Grayson\", \"Jacob\", \"Michael\", \"Benjamin\", \"Carter\", \"James\", \n",
    "    \"Jayden\", \"Logan\", \"Alexander\", \"Caleb\", \"Ryan\", \"Luke\", \"Daniel\", \n",
    "    \"Jack\", \"William\", \"Owen\", \"Gabriel\", \"Matthew\", \"Connor\", \"Jayce\", \n",
    "    \"Isaac\", \"Sebastian\", \"Henry\", \"Muhammad\", \"Cameron\", \"Wyatt\", \n",
    "    \"Dylan\", \"Nathan\", \"Nicholas\", \"Julian\", \"Eli\", \"Levi\", \"Isaiah\", \n",
    "    \"Landon\", \"David\", \"Christian\", \"Andrew\", \"Brayden\", \"John\", \n",
    "    \"Lincoln\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame with the specified distributions\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    {\n",
    "    \"Normal\": np.random.normal(loc=17, scale = np.sqrt(38), size=num_rows),  # Normal(17, variance 38)\n",
    "    \"Uniform\": np.random.uniform(low= -1, high=10, size=num_rows),                 # Uniform(-10, 10)\n",
    "    \"Poisson\": np.random.poisson(6,size=num_rows),                            # Poisson(6)\n",
    "    \"Exponential\": np.random.exponential((1/9),size=num_rows),                  # Exponential(Î»=9)\n",
    "    \"Binomial\": np.random.binomial(n=20, p=0.12,size=num_rows),             # Binomial(n=20, p=0.12)\n",
    "    \"Binary\": np.random.permutation( [1]*int(num_rows*0.24) + [0]*int(num_rows*0.76))  # 24% 1s, shuffled\n",
    "}\n",
    ")\n",
    "\n",
    "X.index = fake_first_names[:num_rows]\n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4816dd-9c9f-4b42-9faf-56c2b450b4c0",
   "metadata": {},
   "source": [
    "Create a data frame of the same data as above except make the binary variable a factor \"DOMESTIC\" vs \"FOREIGN\" for 0 and 1 respectively. In Rstudio you used the `View` function to ensure this worked as desired. In python use .head() on the DataFrame. I recommend creating a copy of the DataFrame and then using the .replace in conjunction with .astype(\"category\") to make the binary variable a factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b71b1aa-e16a-4132-b271-a105a9b3aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Uniform</th>\n",
       "      <th>Poisson</th>\n",
       "      <th>Exponential</th>\n",
       "      <th>Binomial</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sophia</th>\n",
       "      <td>19.146136</td>\n",
       "      <td>8.059100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>2</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emma</th>\n",
       "      <td>20.248167</td>\n",
       "      <td>0.657792</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040585</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olivia</th>\n",
       "      <td>17.212600</td>\n",
       "      <td>1.664471</td>\n",
       "      <td>8</td>\n",
       "      <td>0.079142</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ava</th>\n",
       "      <td>23.937950</td>\n",
       "      <td>-0.799742</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>5</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mia</th>\n",
       "      <td>10.306851</td>\n",
       "      <td>1.941303</td>\n",
       "      <td>7</td>\n",
       "      <td>0.123583</td>\n",
       "      <td>0</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Normal   Uniform  Poisson  Exponential  Binomial    Binary\n",
       "Sophia  19.146136  8.059100        9     0.246700         2  Domestic\n",
       "Emma    20.248167  0.657792        7     0.040585         1  Domestic\n",
       "Olivia  17.212600  1.664471        8     0.079142         1  Domestic\n",
       "Ava     23.937950 -0.799742        3     0.105012         5  Domestic\n",
       "Mia     10.306851  1.941303        7     0.123583         0  Domestic"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert matrix DataFrame to categorical for the binary variable\n",
    "# Make a copy to keep X unchanged- we wanna switch binary col where we have 1's and 0's\n",
    "x_copy=X.copy()\n",
    "\n",
    "\n",
    "# Convert binary column (6th column) to categorical labels\n",
    "x_copy[\"Binary\"]= x_copy[\"Binary\"].replace({0:\"Domestic\",1:\"Foreign\"}).astype(\"category\")\n",
    "\n",
    "# Display first few rows\n",
    "x_copy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd05e5-4162-407c-a4ee-d7b16f0ccf74",
   "metadata": {},
   "source": [
    "Print out a table of the binary variable. Then print out the proportions of \"DOMESTIC\" vs \"FOREIGN\". Pandas DataFrames has a .value_counts() feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8ae57f3-562f-4e73-8eea-40361c93d17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binary\n",
       "Domestic    0.76\n",
       "Foreign     0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_copy[\"Binary\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d5862-6f78-436e-97ec-f98ab801299e",
   "metadata": {},
   "source": [
    "Print out a summary of the whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68f0156a-db34-4bda-997e-e7c72ed16ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Normal     Uniform     Poisson  Exponential    Binomial\n",
      "count  100.000000  100.000000  100.000000   100.000000  100.000000\n",
      "mean    17.358323    3.961668    5.870000     0.110200    2.650000\n",
      "std      5.951614    3.153289    2.480856     0.114190    1.641476\n",
      "min      1.487877   -0.826182    1.000000     0.000303    0.000000\n",
      "25%     13.988447    1.228443    4.000000     0.028539    1.000000\n",
      "50%     17.206678    3.567837    6.000000     0.065005    2.500000\n",
      "75%     21.039802    7.191022    8.000000     0.150016    3.000000\n",
      "max     31.762679    9.990499   12.000000     0.658182    7.000000\n",
      "Binary\n",
      "Domestic    76\n",
      "Foreign     24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_copy.describe())\n",
    "print(x_copy[\"Binary\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb557a15-731f-442f-88d7-c89c34d8e7a4",
   "metadata": {},
   "source": [
    "## Dataframe creation\n",
    "Imagine you are running an experiment with many manipulations. You have 14 levels in the variable \"treatment\" with levels a, b, c, etc. For each of those manipulations you have 3 submanipulations in a variable named \"variation\" with levels A, B, C. Then you have \"gender\" with levels M / F. Then you have \"generation\" with levels Boomer, GenX, Millenial. Then you will have 6 runs per each of these groups. In each set of 6 you will need to select a name without duplication from the appropriate set of names (from the last question). Create a data frame with columns treatment, variation, gender, generation, name and y that will store all the unique unit information in this experiment. Leave y empty because it will be measured as the experiment is executed. In Rstudio you used `rep` function using the `times` argument. For python use np.tile, and np.repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8e615f0-9abe-47ed-8be4-898d653b54a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilana brunner\\AppData\\Local\\Temp\\ipykernel_29500\\2333051876.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  names_df = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], group_keys=False).apply(assign_names_with_index).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>variation</th>\n",
       "      <th>gender</th>\n",
       "      <th>generation</th>\n",
       "      <th>name</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Leroy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Tom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Lee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Herbert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Brittney</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Candice</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     treatment variation gender generation      name   y\n",
       "0            a         A      M     Boomer   Bernard NaN\n",
       "1            a         A      M     Boomer     Leroy NaN\n",
       "2            a         A      M     Boomer       Tom NaN\n",
       "3            a         A      M     Boomer       Lee NaN\n",
       "4            a         A      M     Boomer   Herbert NaN\n",
       "...        ...       ...    ...        ...       ...  ..\n",
       "1507         n         C      F  Millenial  Brittney NaN\n",
       "1508         n         C      F  Millenial    Taylor NaN\n",
       "1509         n         C      F  Millenial   Candice NaN\n",
       "1510         n         C      F  Millenial  Samantha NaN\n",
       "1511         n         C      F  Millenial  Cheyenne NaN\n",
       "\n",
       "[1512 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# he will post code on discord\n",
    "\n",
    "# Define categories \n",
    "treatments = list(\"abcdefghijklmn\") \n",
    "\n",
    "# 14 levels\n",
    "variations = list(\"ABC\") \n",
    "\n",
    "# 3 levels \n",
    "genders = [\"M\", \"F\"] \n",
    "\n",
    "# 2 levels \n",
    "generations = [\"Boomer\", \"GenX\", \"Millenial\"] \n",
    "\n",
    "# 3 levels \n",
    "# Define name sets \n",
    "name_sets = { \"M\": { \"Boomer\": [\"Theodore\", \"Bernard\", \"Gene\", \"Herbert\", \"Ray\", \n",
    "\"Tom\", \"Lee\", \"Alfred\", \"Leroy\", \"Eddie\"], \"GenX\": [\"Marc\", \"Jamie\", \"Greg\", \"Darryl\",\n",
    "\"Tim\", \"Dean\", \"Jon\", \"Chris\", \"Troy\", \"Jeff\"], \"Millenial\": [\"Zachary\", \"Dylan\", \"Christian\",\n",
    "\"Wesley\", \"Seth\", \"Austin\", \"Gabriel\", \"Evan\", \"Casey\", \"Luis\"] }, \"F\": { \"Boomer\": [\"Gloria\", \"Joan\", \"Dorothy\", \n",
    "\"Shirley\", \"Betty\", \"Dianne\", \"Kay\", \"Marjorie\", \"Lorraine\", \"Mildred\"], \"GenX\": [\"Tracy\", \"Dawn\", \"Tina\", \"Tammy\", \n",
    "\"Melinda\", \"Tamara\", \"Tracey\", \"Colleen\", \"Sherri\", \"Heidi\"], \"Millenial\": [\"Samantha\", \"Alexis\", \"Brittany\", \"Lauren\", \n",
    "\"Taylor\", \"Bethany\", \"Latoya\", \"Candice\", \"Brittney\", \"Cheyenne\"] } }\n",
    "\n",
    "\n",
    "# Create experiment DataFrame \n",
    "df = pd.DataFrame({ \"treatment\": np.repeat(treatments, len(variations) * len(genders) * len(generations) * 6), \n",
    "                   \"variation\": np.tile(np.repeat(variations, len(genders) * len(generations) * 6), len(treatments)), \n",
    "                   \"gender\": np.tile(np.repeat(genders, len(generations) * 6), len(treatments) * len(variations)), \n",
    "                   \"generation\": np.tile(np.repeat(generations, 6), len(treatments) * len(variations) * len(genders)), }) \n",
    "\n",
    "# Add a unique identifier to preserve the original order\n",
    "df = df.reset_index().rename(columns={'index': 'orig_index'})\n",
    "\n",
    "# Define a function that assigns 6 unique names per group and returns a DataFrame with the original index\n",
    "def assign_names_with_index(group):\n",
    "    gender_val = group[\"gender\"].iloc[0]  # Extract the group's gender\n",
    "    generation_val = group[\"generation\"].iloc[0]  # Extract the group's generation\n",
    "\n",
    "    # Sample 6 unique names from the appropriate set (without replacement)\n",
    "    names = np.random.choice(name_sets[gender_val][generation_val], 6, replace=False)\n",
    "\n",
    "    # Return a DataFrame with the original indices and the assigned names\n",
    "    return pd.DataFrame({\n",
    "        \"orig_index\": group[\"orig_index\"],\n",
    "        \"name\": names\n",
    "    })\n",
    "\n",
    "# Group by the categorical variables and apply the function\n",
    "names_df = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], group_keys=False).apply(assign_names_with_index).reset_index(drop=True)\n",
    "\n",
    "# Merge the assigned names back into the original DataFrame using the unique identifier\n",
    "df = df.merge(names_df, on=\"orig_index\", how=\"left\")\n",
    "\n",
    "# Restore the original order and remove the temporary identifier\n",
    "df = df.sort_values(\"orig_index\").reset_index(drop=True).drop(columns=[\"orig_index\"])\n",
    "\n",
    "# Add an empty column 'y'\n",
    "df[\"y\"] = np.nan\n",
    "\n",
    "# Display DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a1af36-87fe-4200-a40c-2aeb568a1e6b",
   "metadata": {},
   "source": [
    "Now that you've done it with the np.tile and np.repeat, Try doing this by importing product from the itertools module. This will be analogous to using `expand.grid` function from Rstudio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e35a7-6eec-4434-b88a-7220c503d18e",
   "metadata": {},
   "source": [
    "| **R Function** | **Python Equivalent** |\n",
    "|--------------|-----------------|\n",
    "| `rep(x, times=n)` | `np.repeat(x, n)` |\n",
    "| `rep(x, each=n)` | `np.tile(np.repeat(x, n), times)` |\n",
    "| `rep(x, length.out=n)` | `np.resize(x, n)` |\n",
    "| `expand.grid()` | `itertools.product()` |\n",
    "\n",
    "| **R Function** | **Python Equivalent** | **Use Case** |\n",
    "|--------------|-----------------|-----------|\n",
    "| `rep(x, times=n)` | `np.repeat(x, n)` | Repeat each element **`n` times** in order |\n",
    "| `rep(x, each=n)` | `np.tile(x, n)` | Repeat the full sequence **`n` times** |\n",
    "| `rep(x, length.out=n)` | `np.resize(x, n)` | Repeat `x` but **truncate** or **expand** to length `n` |\n",
    "\n",
    "**`expand.grid()` â†’ `itertools.product()`** for generating **all combinations**  \n",
    "**`rep(..., each=n)` â†’ `np.repeat()`** for **repeating values in order**  \n",
    "**`rep(..., times=n)` â†’ `np.tile()`** for **cycling through values**  \n",
    "**`Combination of `np.repeat()` and `np.tile()`** replaces **nested `rep()`** in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8997381c-d4d5-45ae-86dc-7f1c5ed38705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   treatment variation  gender generation  orig_index       name   y\n",
      "0          A         X    Male       Gen1           0    Michael NaN\n",
      "1          A         X    Male       Gen2           1      Mason NaN\n",
      "2          A         X  Female       Gen1           2  Elizabeth NaN\n",
      "3          A         X  Female       Gen2           3        Ava NaN\n",
      "4          A         Y    Male       Gen1           4       John NaN\n",
      "5          A         Y    Male       Gen2           5      Lucas NaN\n",
      "6          A         Y  Female       Gen1           6       Mary NaN\n",
      "7          A         Y  Female       Gen2           7     Olivia NaN\n",
      "8          B         X    Male       Gen1           8    William NaN\n",
      "9          B         X    Male       Gen2           9     Elijah NaN\n",
      "10         B         X  Female       Gen1          10    Barbara NaN\n",
      "11         B         X  Female       Gen2          11     Sophia NaN\n",
      "12         B         Y    Male       Gen1          12      James NaN\n",
      "13         B         Y    Male       Gen2          13       Noah NaN\n",
      "14         B         Y  Female       Gen1          14       Mary NaN\n",
      "15         B         Y  Female       Gen2          15       Emma NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilana brunner\\AppData\\Local\\Temp\\ipykernel_29500\\1365038993.py:52: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  names_df = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], group_keys=False).apply(assign_names_with_index).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# he is gonna post code \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# Define categorical variables\n",
    "treatments = [\"A\", \"B\"]\n",
    "variations = [\"X\", \"Y\"]\n",
    "genders = [\"Male\", \"Female\"]\n",
    "generations = [\"Gen1\", \"Gen2\"]\n",
    "\n",
    "# Create a DataFrame using itertools.product\n",
    "df = pd.DataFrame(product(treatments, variations, genders, generations),\n",
    "                  columns=[\"treatment\", \"variation\", \"gender\", \"generation\"])\n",
    "\n",
    "# Assign unique index\n",
    "df[\"orig_index\"] = df.index  \n",
    "\n",
    "# Define name sets for each gender and generation\n",
    "name_sets = {\n",
    "    \"Male\": {\n",
    "        \"Gen1\": [\"John\", \"Michael\", \"David\", \"James\", \"Robert\", \"William\"],\n",
    "        \"Gen2\": [\"Liam\", \"Noah\", \"Oliver\", \"Elijah\", \"Lucas\", \"Mason\"]\n",
    "    },\n",
    "    \"Female\": {\n",
    "        \"Gen1\": [\"Mary\", \"Patricia\", \"Jennifer\", \"Linda\", \"Barbara\", \"Elizabeth\"],\n",
    "        \"Gen2\": [\"Olivia\", \"Emma\", \"Ava\", \"Sophia\", \"Isabella\", \"Mia\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to assign names dynamically based on group size\n",
    "def assign_names_with_index(group):\n",
    "    gender_val = group[\"gender\"].iloc[0]\n",
    "    generation_val = group[\"generation\"].iloc[0]\n",
    "    \n",
    "    group_size = len(group)\n",
    "    available_names = name_sets[gender_val][generation_val]\n",
    "    \n",
    "    # Ensure we don't sample more names than available\n",
    "    num_names = min(group_size, len(available_names))\n",
    "    \n",
    "    # Sample unique names\n",
    "    names = np.random.choice(available_names, num_names, replace=False)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"orig_index\": group[\"orig_index\"].values[:num_names],  \n",
    "        \"name\": names\n",
    "    })\n",
    "\n",
    "# Apply the function to assign names\n",
    "names_df = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], group_keys=False).apply(assign_names_with_index).reset_index(drop=True)\n",
    "\n",
    "# Merge assigned names back into original DataFrame\n",
    "df = df.merge(names_df, on=\"orig_index\", how=\"left\").sort_values(\"orig_index\").reset_index(drop=True)\n",
    "\n",
    "# Add empty column 'y'\n",
    "df[\"y\"] = np.nan\n",
    "\n",
    "# Display final DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5d2ba-4e03-40b8-a65b-2730add003cf",
   "metadata": {},
   "source": [
    "## Basic Binary Classification Modeling\n",
    "\n",
    "Load the famous `iris` data frame into the namespace. In Rstudio you used the `skim` function from the package `skimr` to provide a summary of the columns. In python we will use df.describe() and the ProfileReport from the ydata-profiling package. The `iris` data set is not available in base python, but we can get this data from the sklearn package. Write a few descriptive sentences about the distributions using the code below in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90d8e98a-8bca-4fed-8bdb-e38e3af138f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install scikit-learn by uncommenting the code below\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a425f989-a578-4f22-b22f-6a78037cdac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ydata-profiling[notebook]\n",
      "  Downloading ydata_profiling-4.12.2-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<1.16,>=1.4.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (1.13.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (2.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.5 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (3.9.2)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (2.8.2)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (6.0.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (3.1.4)\n",
      "Collecting visions<0.8.0,>=0.7.5 (from visions[type_image_path]<0.8.0,>=0.7.5->ydata-profiling[notebook])\n",
      "  Downloading visions-0.7.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.2,>=1.16.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (1.26.4)\n",
      "Collecting htmlmin==0.1.12 (from ydata-profiling[notebook])\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting phik<0.13,>=0.11.1 (from ydata-profiling[notebook])\n",
      "  Downloading phik-0.12.4-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (4.66.5)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (0.13.2)\n",
      "Collecting multimethod<2,>=1.4 (from ydata-profiling[notebook])\n",
      "  Downloading multimethod-1.12-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (0.14.2)\n",
      "Collecting typeguard<5,>=3 (from ydata-profiling[notebook])\n",
      "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting imagehash==4.3.1 (from ydata-profiling[notebook])\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting wordcloud>=1.9.3 (from ydata-profiling[notebook])\n",
      "  Downloading wordcloud-1.9.4-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting dacite>=1.8 (from ydata-profiling[notebook])\n",
      "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (1.0.0)\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ydata-profiling[notebook]) (7.8.1)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling[notebook]) (1.7.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling[notebook]) (10.4.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]) (8.27.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling[notebook]) (2.1.3)\n",
      "Requirement already satisfied: notebook in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter>=1.0.0->ydata-profiling[notebook]) (7.2.2)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter>=1.0.0->ydata-profiling[notebook]) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter>=1.0.0->ydata-profiling[notebook]) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter>=1.0.0->ydata-profiling[notebook]) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter>=1.0.0->ydata-profiling[notebook]) (6.28.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from matplotlib>=3.5->ydata-profiling[notebook]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from matplotlib>=3.5->ydata-profiling[notebook]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from matplotlib>=3.5->ydata-profiling[notebook]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from matplotlib>=3.5->ydata-profiling[notebook]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from matplotlib>=3.5->ydata-profiling[notebook]) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from matplotlib>=3.5->ydata-profiling[notebook]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from matplotlib>=3.5->ydata-profiling[notebook]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling[notebook]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling[notebook]) (2023.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling[notebook]) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling[notebook]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling[notebook]) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling[notebook]) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling[notebook]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling[notebook]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling[notebook]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling[notebook]) (2024.8.30)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from statsmodels<1,>=0.13.2->ydata-profiling[notebook]) (0.5.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from tqdm<5,>=4.48.2->ydata-profiling[notebook]) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from visions<0.8.0,>=0.7.5->visions[type_image_path]<0.8.0,>=0.7.5->ydata-profiling[notebook]) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from visions<0.8.0,>=0.7.5->visions[type_image_path]<0.8.0,>=0.7.5->ydata-profiling[notebook]) (3.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from patsy>=0.5.6->statsmodels<1,>=0.13.2->ydata-profiling[notebook]) (1.16.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (6.4.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (25.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (1.2.1)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from qtconsole->jupyter>=1.0.0->ydata-profiling[notebook]) (2.4.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0->ydata-profiling[notebook]) (305.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.4.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.27.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (75.1.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->ydata-profiling[notebook]) (2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]) (0.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (21.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (0.1.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook])\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook])\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.1)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook])\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook])\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\ilana brunner\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->ydata-profiling[notebook]) (1.2.3)\n",
      "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "Downloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
      "Downloading multimethod-1.12-py3-none-any.whl (10 kB)\n",
      "Downloading phik-0.12.4-cp312-cp312-win_amd64.whl (666 kB)\n",
      "   ---------------------------------------- 0.0/666.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 666.4/666.4 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "Downloading visions-0.7.6-py3-none-any.whl (104 kB)\n",
      "Downloading wordcloud-1.9.4-cp312-cp312-win_amd64.whl (301 kB)\n",
      "Downloading ydata_profiling-4.12.2-py2.py3-none-any.whl (390 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27091 sha256=f342c5a2276af9e6d0b8c9c923fe663ebb73bfc7b61b6811c229d335725a1775\n",
      "  Stored in directory: c:\\users\\ilana brunner\\appdata\\local\\pip\\cache\\wheels\\5f\\d4\\d7\\4189b07b5902ee9f3ce0dbb14909fbe8037c39d6c63ffd49c9\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, webcolors, uri-template, typeguard, multimethod, fqdn, dacite, imagehash, wordcloud, visions, phik, isoduration, ydata-profiling\n",
      "Successfully installed dacite-1.9.2 fqdn-1.5.1 htmlmin-0.1.12 imagehash-4.3.1 isoduration-20.11.0 multimethod-1.12 phik-0.12.4 typeguard-4.4.1 uri-template-1.3.0 visions-0.7.6 webcolors-24.11.1 wordcloud-1.9.4 ydata-profiling-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install ydata-profile by uncommenting the code below\n",
    "%pip install -U ydata-profiling[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e432f-4c74-402e-8ffd-94086acea991",
   "metadata": {},
   "source": [
    "### **Comparing the `iris` Dataset in R vs Python**\n",
    "| Feature  | **R (`datasets::iris`)**  | **Python (`sklearn.datasets.load_iris()`)**  |\n",
    "|----------|-------------------------|--------------------------------|\n",
    "| **Total Rows**  | 150 | 150 |\n",
    "| **Columns (Features)** | 5 (`Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`, `Species`) | 5 (`sepal length (cm)`, `sepal width (cm)`, `petal length (cm)`, `petal width (cm)`, `species`) |\n",
    "| **Species Encoding**  | `\"setosa\"`, `\"versicolor\"`, `\"virginica\"` (Categorical Factor) | `0` (setosa), `1` (versicolor), `2` (virginica) (Numerical Encoding) |\n",
    "| **Data Type for Species** | Factor (Categorical) | Integer (0,1,2) |\n",
    "| **Data Loading Method** | `data(iris)` (built-in dataset) | `datasets.load_iris()` (from `sklearn`) |\n",
    "\n",
    "### **Key Differences**\n",
    "- **Species Encoding:**  \n",
    "  - **R uses categorical factor labels (`setosa`, `versicolor`, `virginica`).**  \n",
    "  - **Python (`sklearn`) encodes species numerically as `0`, `1`, and `2`.**\n",
    "- **Column Names:**  \n",
    "  - **R:** `Sepal.Length`, `Sepal.Width`, etc.  \n",
    "  - **Python:** `sepal length (cm)`, `sepal width (cm)`, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee083aa6-2ddd-42c5-9fda-69f5109800d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec0325040ea4b4a8f099f57e00bb91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilana brunner\\anaconda3\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\discretize_pandas.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  discretized_df.loc[:, column] = self._discretize_column(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07676ee04aac4f109d6ddbaeb1269f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939259866096424fbfcb19c32cbd68da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f41d0f642421a8b5352be38955a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import ydata_profiling  \n",
    "\n",
    "# Load the famous Iris dataset\n",
    "Iris = datasets.load_iris()\n",
    "#get length and width\n",
    "df_iris = pd.DataFrame(Iris.data, columns = Iris.feature_names)\n",
    "# now add species column\n",
    "df_iris[\"species\"]=Iris.target\n",
    "df_iris.describe()\n",
    "\n",
    "profile = ydata_profiling.ProfileReport(df_iris, title = \"iris summary\", explorative= True)\n",
    "# Generate the profiling report (Uncomment to generate HTML file)\n",
    "profile.to_file(\"iris_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd248b90-f54e-469f-9136-4c7bef72170a",
   "metadata": {},
   "source": [
    "TO-DO: describe this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa24ea7-7952-4619-8a64-bf532fed741e",
   "metadata": {},
   "source": [
    "Sepal Length:\n",
    "min= 4.3\n",
    "max= 7.9\n",
    "mean = 5.843333\n",
    "\n",
    "sepal width:\n",
    "\n",
    "min=2\n",
    "max=4.4\n",
    "mean= 3.057333\n",
    "\n",
    "petal L:\n",
    "min=1\n",
    "max=6.9\n",
    "mean=3.578\n",
    "\n",
    "petal W:\n",
    "min=.1\n",
    "max=2.5\n",
    "mean=1.993333\n",
    "\n",
    "3 distinct species \n",
    "2.0% distinct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9410a-f7f6-4fdb-a18c-722947bfc29b",
   "metadata": {},
   "source": [
    "The outcome / label / response is `Species`. This is what we will be trying to predict. However, we only care about binary classification between \"setosa\" and \"versicolor\" for the purposes of this exercise. Thus the first order of business is to drop one class. Let's drop the data for the level \"virginica\" from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb2614d6-1cdc-44d9-a086-2c0cd62a42ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   species  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Filter out \"virginica\" from the dataset\n",
    "df_iris_binary= df_iris[df_iris[\"species\"] != 2 ].copy() # form of filtering\n",
    "print(df_iris_binary.head())\n",
    "print(df_iris_binary[\"species\"].unique()) #shows only 2 unique values 0 or 1 aka got rid of virginica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf18a6b5-ba05-47ef-9753-62802ce454f5",
   "metadata": {},
   "source": [
    "Now create a vector `y` that is length the number of remaining rows in the data frame whose entries are 0 if \"setosa\" and 1 if \"versicolor\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6b8332c-156d-46a2-a936-137d41786e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary target vector `y` (0 for setosa, 1 for versicolor)\n",
    "y = (df_iris_binary[\"species\"]==1).astype(int)\n",
    "y.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb64b66-f9de-4c71-9772-6a9e6eb92adc",
   "metadata": {},
   "source": [
    "Write a function `mode` returning the sample mode of a vector of numeric values. Use np.random.choice from NumPy and import Counter from the collections module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b464e6b-d637-437c-acba-278cd9a2f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of sample letters: b\n",
      "Mode of y: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define mode function\n",
    "def mode(v):\n",
    "    return Counter(v).most_common(1)[0][0]\n",
    "\n",
    "    # Test with a random sample (equivalent to `sample(letters, 1000, replace=TRUE)`)\n",
    "    \n",
    "sample_data = np.random.choice(list(\"abcdefghijklmnopqrstuvwxyz\"), 1000, replace=True)\n",
    "print(\"Mode of sample letters:\", mode(sample_data))\n",
    "\n",
    "# Test with binary target vector `y`\n",
    "\n",
    "print(\"Mode of y:\", mode(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2637b47-66d9-4f86-9615-33e45d34a4ac",
   "metadata": {},
   "source": [
    "Fit a threshold model to `y` using the feature `Sepal.Length`. Write your own code to do this. What is the estimated value of the threshold parameter? Save the threshold value as `threshold`. Hint: use np.zeros and np.sum from Numpy. You will need to use a for loop using the range() function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c828658-e5c0-45a7-af97-38804d222777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for classification: 5.4\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant data\n",
    "sepal_length = df_iris_binary[\"sepal length (cm)\"].values  # Feature\n",
    "y_values = y.values  # Target labels (0 or 1)\n",
    "n = len(sepal_length)  # Number of samples\n",
    "\n",
    "# Initialize matrix to store threshold values and corresponding error counts\n",
    "num_errors_by_parameter = np.zeros((n, 2))\n",
    "\n",
    "# Loop over all possible threshold values\n",
    "for i in range(n):\n",
    "    threshold = sepal_length[i]  # Set current threshold\n",
    "    num_errors = np.sum((sepal_length > threshold) != y_values)  # Count classification errors\n",
    "    num_errors_by_parameter[i] = [threshold, num_errors]  # Store values\n",
    "\n",
    "# Sort by number of errors\n",
    "num_errors_by_parameter = num_errors_by_parameter[num_errors_by_parameter[:, 1].argsort()]\n",
    "\n",
    "# Get the threshold with the least number of errors\n",
    "best_threshold = num_errors_by_parameter[0, 0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal threshold for classification: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251490a-2bd4-41db-a4d5-439fe0880944",
   "metadata": {},
   "source": [
    "What is the total number of errors this model makes? This requires a couple of minor modifications to the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0fe81982-cf59-49d0-b7b9-579b7f639124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for classification: 5.4\n",
      "Total number of errors across all thresholds: 2796\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant data\n",
    "sepal_length = df_iris_binary[\"sepal length (cm)\"].values  # Feature\n",
    "y_values = y.values  # Target labels (0 or 1)\n",
    "n = len(sepal_length)  # Number of samples\n",
    "\n",
    "# Initialize matrix to store threshold values and corresponding error counts\n",
    "num_errors_by_parameter = np.zeros((n, 2))\n",
    "total_errors = 0\n",
    "# Loop over all possible threshold values\n",
    "for i in range(n):\n",
    "    threshold = sepal_length[i]  # Set current threshold\n",
    "    \n",
    "    num_errors = np.sum((sepal_length > threshold) != y_values)  # Count classification errors\n",
    "    \n",
    "    # Store threshold and corresponding errors\n",
    "    num_errors_by_parameter[i] = [threshold, num_errors]\n",
    "    \n",
    "    # Accumulate total errors across all thresholds\n",
    "    total_errors += num_errors\n",
    "\n",
    "\n",
    "# Sort by number of errors to find the best threshold\n",
    "num_errors_by_parameter = num_errors_by_parameter[num_errors_by_parameter[:, 1].argsort()]\n",
    "best_threshold = num_errors_by_parameter[0, 0]  # Best threshold with the least errors\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal threshold for classification: {best_threshold}\")\n",
    "print(f\"Total number of errors across all thresholds: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1454817-710a-41be-981e-be1966366b1c",
   "metadata": {},
   "source": [
    "Does the threshold model's performance make sense given the following summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b40fb82f-80c7-4b13-b242-298777096815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for classification: 5.4\n",
      "\n",
      "Summary statistics for Setosa Sepal Length:\n",
      "count    50.00000\n",
      "mean      5.00600\n",
      "std       0.35249\n",
      "min       4.30000\n",
      "25%       4.80000\n",
      "50%       5.00000\n",
      "75%       5.20000\n",
      "max       5.80000\n",
      "Name: sepal length (cm), dtype: float64\n",
      "\n",
      "Summary statistics for Versicolor Sepal Length:\n",
      "count    50.000000\n",
      "mean      5.936000\n",
      "std       0.516171\n",
      "min       4.900000\n",
      "25%       5.600000\n",
      "50%       5.900000\n",
      "75%       6.300000\n",
      "max       7.000000\n",
      "Name: sepal length (cm), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the best threshold found earlier\n",
    "print(f\"Optimal threshold for classification: {best_threshold}\")\n",
    "\n",
    "# Summary statistics for setosa and versicolor Sepal.Length\n",
    "setosa_summary = df_iris_binary[df_iris_binary[\"species\"] == 0][\"sepal length (cm)\"].describe()\n",
    "versicolor_summary = df_iris_binary[df_iris_binary[\"species\"] == 1][\"sepal length (cm)\"].describe()\n",
    "\n",
    "# Print summaries\n",
    "print(\"\\nSummary statistics for Setosa Sepal Length:\")\n",
    "print(setosa_summary)\n",
    "\n",
    "print(\"\\nSummary statistics for Versicolor Sepal Length:\")\n",
    "print(versicolor_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f16a3-7780-49d8-a14d-614a87eb2d8f",
   "metadata": {},
   "source": [
    "TO-DO: Write your answer here in English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901db688-69b7-4362-9e05-93ad49d6843d",
   "metadata": {},
   "source": [
    "well setosa\" ranges from 4.3 to 5.8, with a median of 5.0 and a mean of 5.006 and \"versicolor\" ranges from 4.9 to 7.0, with a median of 5.9 and a mean of 5.936 and threshold is 5.35 which makes sense because most of setosa is below it and most of versicolor is above it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df601bb-9732-4bb9-b7a7-a24e28987d2e",
   "metadata": {},
   "source": [
    "Create the function `g` explicitly that can predict `y` from `x` being a new `Sepal.Length`. Hint: use np.where from Numpy ... this can also be down using a lambda function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01c890a3-8d19-4867-a73a-d51a69708597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function `g` for threshold-based prediction\n",
    "\n",
    "def g(x):\n",
    "    return np.where(x > best_threshold, 1, 0)\n",
    "\n",
    "#create test value 0 is less than threshold 1 is more than threshold\n",
    "test_val = 12\n",
    "g(test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f89175c-c175-44b4-96d9-e4ddb91c9a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way to do in one line\n",
    "\n",
    "g = lambda x:np.where(x >best_threshold, 1, 0)\n",
    "#create test value 0 is less than threshold 1 is more than threshold\n",
    "test_val = 1\n",
    "g(test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f375552-2f9e-44b3-ab3b-8c9dcea38656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
